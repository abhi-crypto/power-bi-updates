name: AI Power BI Summarizer (No Card Required)
on:
  schedule:
    - cron: '45 0 * * *'
  workflow_dispatch:

jobs:
  ai-summarize:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Tools
        run: pip install groq requests beautifulsoup4

      - name: AI Processing
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          python - <<EOF
          import os, requests, time
          from groq import Groq
          from bs4 import BeautifulSoup
          from datetime import datetime

          # 1. Setup Groq (Free & No Credit Card)
          client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
          HEADERS = {'User-Agent': 'Mozilla/5.0 (Linux; Android 14; SM-X910) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

          def fetch_summary(url):
              try:
                  page = requests.get(url, headers=HEADERS, timeout=20)
                  soup = BeautifulSoup(page.text, 'html.parser')
                  content = soup.find('article') or soup.find('div', {'class': 'entry-content'}) or soup.body
                  text = content.get_text(separator=' ', strip=True)[:5000]
                  
                  completion = client.chat.completions.create(
                      model="llama-3.3-70b-versatile",
                      messages=[{"role": "user", "content": f"Summarize this Power BI blog in 4 technical bullet points for a professional. Text: {text}"}]
                  )
                  return completion.choices[0].message.content
              except Exception as e:
                  return f"Summary skipped: {str(e)}"

          # 2. Get latest 3 links
          feed = requests.get("https://powerbi.microsoft.com/en-us/blog/feed/", headers=HEADERS).text
          links = [l.split('</link>')[0] for l in feed.split('<link>')[1:4]]

          # 3. Build Section
          new_section = f"\n## ðŸ¤– AI Summary: {datetime.now().strftime('%Y-%m-%d')}\n"
          for url in links:
              new_section += f"### [Link]({url})\n{fetch_summary(url)}\n\n---\n"
              time.sleep(5) # Delay to be polite

          # 4. Save to File
          filename = "AI_SUMMARIES.md"
          existing = open(filename, "r").read() if os.path.exists(filename) else ""
          with open(filename, "w") as f:
              f.write("# Power BI AI Insight Lab\n" + new_section + existing.replace("# Power BI AI Insight Lab", ""))
          EOF

      - name: Save to GitHub
        run: |
          git config user.name "AI Assistant"
          git config user.email "ai@github.com"
          git add AI_SUMMARIES.md
          git commit -m "Groq AI Summary Generated" || exit 0
          git push
