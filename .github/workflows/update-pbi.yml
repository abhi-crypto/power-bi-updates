name: Power BI Link Sync (Absolute Fix)
on:
  schedule:
    - cron: '15 0 * * *'
  workflow_dispatch:

jobs:
  update-links:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install requests beautifulsoup4 lxml

      - name: Fetch and Fix Links
        run: |
          python - <<EOF
          import requests
          import os
          from bs4 import BeautifulSoup
          from datetime import datetime
          from urllib.parse import urljoin

          HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
          BASE_URL = "https://powerbi.microsoft.com"
          FEED_URL = "https://powerbi.microsoft.com/en-us/blog/feed/"
          FILENAME = "README.md"

          def get_valid_links():
              try:
                  res = requests.get(FEED_URL, headers=HEADERS, timeout=20)
                  soup = BeautifulSoup(res.text, 'xml')
                  items = soup.find_all('item')[:5]
                  
                  valid_markdown_list = []
                  for item in items:
                      title = item.title.text.strip()
                      link = item.link.text.strip()
                      
                      # 1. Ensure Absolute URL
                      # If link starts with '/', this joins it to the BASE_URL
                      full_url = urljoin(BASE_URL, link)
                      
                      # 2. Strict Validation Check
                      try:
                          check = requests.get(full_url, headers=HEADERS, timeout=10)
                          if check.status_code == 200:
                              valid_markdown_list.append(f"* [{title}]({full_url})")
                          else:
                              print(f"Skipping {full_url} - Status: {check.status_code}")
                      except:
                          continue
                          
                  return valid_markdown_list
              except Exception as e:
                  print(f"Error: {e}")
                  return []

          new_posts = get_valid_links()
          if new_posts:
              today = datetime.now().strftime('%Y-%m-%d')
              header = "# Power BI Link Archive\n\n"
              new_content = f"## ðŸ“… Updates Pulled: {today}\n" + "\n".join(new_posts) + "\n\n---\n"
              
              old_data = ""
              if os.path.exists(FILENAME):
                  with open(FILENAME, "r") as f:
                      old_data = f.read().replace("# Power BI Link Archive", "").strip()
              
              with open(FILENAME, "w") as f:
                  f.write(header + new_content + "\n" + old_data)
          EOF

      - name: Commit and Push
        run: |
          git config user.name "Link Fixer Bot"
          git config user.email "bot@github.com"
          git add README.md
          git commit -m "Fixed Relative Links: $(date +'%Y-%m-%d')" || exit 0
          git push
